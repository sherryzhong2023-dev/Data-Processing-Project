Research question: Analysis of Contralateral Processing in Human Sensory Pathways using MEG/EEG

Outline: Using publicly available Magnetoencephalography (MEG) and Electroencephalography (EEG) sample data from the MNE-Python library, the project implemented the preprocessing pipeline, such as filtering and artifact rejection via Independent Component Analysis (ICA). The central steps that visualise the contralateral processing mechanisms involved calculating the difference evoked fields between lateralized stimuli (Visual Left/Right and Auditory Left/Right). The results demonstrated the localization and functional specialization of the primary visual cortex in the occipital lobe and primary auditory cortex in the temporal lobe under the contralateral processing principle.

Introduction:

- The Contralateral Processing: The principle in human neurobiology in which the information received on one side of the body or visual field is routed and processed primarily to the sensory processing areas located in the opposite cerebral hemisphere. For example, within the visual pathway, stimuli presented to the left visual field are sent to the right occipital cortex. Similarly, within the auditory pathway, sounds delivered to the left ear are processed mainly by the right temporal cortex.

- The neural events that engage in contralateral processing are extremely fast, occurring within the first 100 to 200 milliseconds after the presentation of the visual/auditory stimulus. To accurately capture the speed and initial spatial location of these events, neuroscientific techniques with good temporal resolution are needed, such as Magnetoencephalography (MEG) and Electroencephalography (EEG). Both MEG and EEG offer high temporal resolution with precision in milliseconds, which allows people to track the exact moment information arrives in the cortex. MEG is also particularly good for functional localization, which is the identification of the regions where the signal comes from, because magnetic fields are less distorted by the skull than electrical fields that are captured by EEG.

Data: A visual and auditory event-related EEG/MEG dataset from the sample dataset provided by the MNE-Python library. The experiment presented subjects with rapid checkerboard patterns (Visual Left/Right) and tones (Auditory Left/Right), which evoke the targeted sensory responses.

Project goal: Learn how to process, analyze, and visualize EEG/MEG data using the MNE-Python library. 

Method: Follow the MNE tutorial on the preprocessing of MEG/EEG data to gain an idea about the general layout of the dataset.

o loading the data: inspecting the raw data, including the signal plots and Power Spectral Density (PSD) that shows the distribution of frequency waves
o filtering and artifact rejection: clean up the noisy raw data filled with biological artifacts, such as eye blinks and muscle movements. These artifacts generate electrical or magnetic fields that are much larger than the subtle signals produced by neuronal activity, forming large spikes in the raw data.
o epoching for standard and deviant tones: employing the Stimulus Trigger (STI) channel, which contains the precise timing codes of the experiment, to cut the data into short epochs centered around the stimulus onset.
o averaging to produce evoked responses (ERFs): averaging events from one condition would cancel out all random noise of background brain activity, leaving only the consistent signal reliably evoked by the stimulus.
o visualizing and quantifying the contralateral processing principle: Difference Wave calculation cancels out all general brain activity shared by both conditions in the contralateral and ipsilateral processing, leaving only the signal related to the side of processing. visualisation utilises the Difference Topomap, which shows where and when the isolated difference signal is strongest.

Results: The final steps after the preprocessing employed the difference wave calculation (Contralateral Response - Ipsilateral Response) to isolate the specific lateralized effect, which showcases the contralateral processing in auditory/visual pathways. The visualisation is enabled by the difference topomap that shows activation strengths across the scalp.

- Visual Evoked Field (VEF): The difference wave topography (plotted at the P100 latency) showed a strong, lateralized dipolar pattern over the posterior (occipital) scalp. The result clearly showed a difference in activity over the back of the head, confirming the specialization of the visual cortex for contralateral field input.

- Auditory Evoked Field (AEF): The difference wave topography (plotted at the N100 latency) showed a distinct, lateralized dipolar pattern over the lateral/temporal regions of the head. This pattern confirmed that the brain activity specific to sound localization was correctly found in the auditory cortex.

Conclusion: This project implemented the preprocessing and analysis pipeline that cleans up and interprets neurophysiological data. By generating different topomaps for both visual and auditory contrasts, the project demonstrates the fundamental contralateral processing principle, along with providing me the opportunity to learn and apply signal processing techniques and functional localization in neuroscientific methodology.
