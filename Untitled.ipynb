{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35a95f90-6014-4590-b293-c3aa28adbb8c",
   "metadata": {},
   "source": [
    "# Project Tasks\n",
    "1. Load raw MEG data (CTF format) — combining runs, reading noise recordings. \n",
    "2. Preprocess data — set channel types, annotate bad segments, compute and apply projectors (EOG, saccades), filter, etc. \n",
    "3. Epoching — find stimulus events, define time windows (tmin, tmax), drop bad epochs, baseline correction. \n",
    "4. Averaging to get evoked responses (e.g. “standard” vs “deviant” conditions) \n",
    "5. Filtering on evoked data (low-pass) for clarity in the example \n",
    "6. Source estimation — build forward model, noise covariance, inverse operator, then apply inverse (dSPM) to map sensor signals into source space. \n",
    "7. Plot results / inspect — sensor topographies, time courses, source estimates. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd56e7ce-251e-4c57-978c-82640f52fd09",
   "metadata": {},
   "source": [
    "**The Experiment**\n",
    "\n",
    "One subject, 2 acquisition runs 6 minutes each.\n",
    "\n",
    "Each run contains 200 regular beeps and 40 easy deviant beeps.\n",
    "\n",
    "Random ISI: between 0.7s and 1.7s seconds, uniformly distributed.\n",
    "\n",
    "Button pressed when detecting a deviant with the right index finger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e1272b4-3f5e-4a2e-be04-bcec1643f1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "from mne import combine_evoked\n",
    "from mne.io import read_raw_ctf\n",
    "from mne.minimum_norm import apply_inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37de9606-c7cc-41a9-b5c6-ae7368dd3acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sherryzhong/mne_data/MNE-brainstorm-data/bst_auditory\n"
     ]
    }
   ],
   "source": [
    "# load the Brainstorm auditory dataset\n",
    "data_path = mne.datasets.brainstorm.bst_auditory.data_path()\n",
    "print(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f26864ba-503a-4127-a147-7d5260593c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the 2 runs of MEG data\n",
    "raw_fname1 = data_path / \"MEG\" / \"bst_auditory\" / \"S01_AEF_20131218_01.ds\"\n",
    "raw_fname2 = data_path / \"MEG\" / \"bst_auditory\" / \"S01_AEF_20131218_02.ds\"\n",
    "\n",
    "# load empty room measurement recorded with no subject inside to estimate environmental noise\n",
    "erm_fname = data_path / \"MEG\" / \"bst_auditory\" / \"S01_Noise_20131218_01.ds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33b336d8-3992-48c5-8d82-e0a14ba5688e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ds directory : /Users/sherryzhong/mne_data/MNE-brainstorm-data/bst_auditory/MEG/bst_auditory/S01_AEF_20131218_01.ds\n",
      "    res4 data read.\n",
      "    hc data read.\n",
      "    Separate EEG position data file read.\n",
      "    Quaternion matching (desired vs. transformed):\n",
      "       2.51   74.26    0.00 mm <->    2.51   74.26   -0.00 mm (orig :  -56.69   50.20 -264.38 mm) diff =    0.000 mm\n",
      "      -2.51  -74.26    0.00 mm <->   -2.51  -74.26   -0.00 mm (orig :   50.89  -52.31 -265.88 mm) diff =    0.000 mm\n",
      "     108.63    0.00    0.00 mm <->  108.63    0.00    0.00 mm (orig :   67.41   77.68 -239.53 mm) diff =    0.000 mm\n",
      "    Coordinate transformations established.\n",
      "    Reading digitizer points from ['/Users/sherryzhong/mne_data/MNE-brainstorm-data/bst_auditory/MEG/bst_auditory/S01_AEF_20131218_01.ds/S01_20131218_01.pos']...\n",
      "    Polhemus data for 3 HPI coils added\n",
      "    Device coordinate locations for 3 HPI coils added\n",
      "    5 extra points added to Polhemus data.\n",
      "    Measurement info composed.\n",
      "Finding samples for /Users/sherryzhong/mne_data/MNE-brainstorm-data/bst_auditory/MEG/bst_auditory/S01_AEF_20131218_01.ds/S01_AEF_20131218_01.meg4: \n",
      "    System clock channel is available, checking which samples are valid.\n",
      "    360 x 2400 = 864000 samples from 340 chs\n",
      "Current compensation grade : 3\n",
      "ds directory : /Users/sherryzhong/mne_data/MNE-brainstorm-data/bst_auditory/MEG/bst_auditory/S01_AEF_20131218_02.ds\n",
      "    res4 data read.\n",
      "    hc data read.\n",
      "    Separate EEG position data file read.\n",
      "    Quaternion matching (desired vs. transformed):\n",
      "       2.64   74.60    0.00 mm <->    2.64   74.60   -0.00 mm (orig :  -58.07   49.23 -263.11 mm) diff =    0.000 mm\n",
      "      -2.64  -74.60    0.00 mm <->   -2.64  -74.60   -0.00 mm (orig :   49.94  -53.82 -265.07 mm) diff =    0.000 mm\n",
      "     108.24    0.00    0.00 mm <->  108.24   -0.00    0.00 mm (orig :   66.67   76.99 -243.39 mm) diff =    0.000 mm\n",
      "    Coordinate transformations established.\n",
      "    Reading digitizer points from ['/Users/sherryzhong/mne_data/MNE-brainstorm-data/bst_auditory/MEG/bst_auditory/S01_AEF_20131218_02.ds/S01_20131218_01.pos']...\n",
      "    Polhemus data for 3 HPI coils added\n",
      "    Device coordinate locations for 3 HPI coils added\n",
      "    5 extra points added to Polhemus data.\n",
      "    Measurement info composed.\n",
      "Finding samples for /Users/sherryzhong/mne_data/MNE-brainstorm-data/bst_auditory/MEG/bst_auditory/S01_AEF_20131218_02.ds/S01_AEF_20131218_02.meg4: \n",
      "    System clock channel is available, checking which samples are valid.\n",
      "    360 x 2400 = 864000 samples from 340 chs\n",
      "Current compensation grade : 3\n",
      "ds directory : /Users/sherryzhong/mne_data/MNE-brainstorm-data/bst_auditory/MEG/bst_auditory/S01_Noise_20131218_01.ds\n",
      "    res4 data read.\n",
      "    hc data read.\n",
      "    Separate EEG position data file read.\n",
      "    Quaternion matching (desired vs. transformed):\n",
      "       0.00   80.00    0.00 mm <->    0.00   80.00    0.00 mm (orig :  -56.57   56.57 -270.00 mm) diff =    0.000 mm\n",
      "       0.00  -80.00    0.00 mm <->    0.00  -80.00    0.00 mm (orig :   56.57  -56.57 -270.00 mm) diff =    0.000 mm\n",
      "      80.00    0.00    0.00 mm <->   80.00   -0.00    0.00 mm (orig :   56.57   56.57 -270.00 mm) diff =    0.000 mm\n",
      "    Coordinate transformations established.\n",
      "    Polhemus data for 3 HPI coils added\n",
      "    Device coordinate locations for 3 HPI coils added\n",
      "    Measurement info composed.\n",
      "Finding samples for /Users/sherryzhong/mne_data/MNE-brainstorm-data/bst_auditory/MEG/bst_auditory/S01_Noise_20131218_01.ds/S01_Noise_20131218_01.meg4: \n",
      "    System clock channel is available, checking which samples are valid.\n",
      "    15 x 4800 = 72000 samples from 301 chs\n",
      "Current compensation grade : 3\n"
     ]
    }
   ],
   "source": [
    "# get the time point of when the first run ends\n",
    "raw = read_raw_ctf(raw_fname1)\n",
    "run1_offset = raw.n_times\n",
    "\n",
    "# combine the two runs, ignore different device<->head transforms\n",
    "raw_combined = mne.io.concatenate_raws([raw, read_raw_ctf(raw_fname2)], on_mismatch=\"ignore\")\n",
    "\n",
    "# read the environmental noise data\n",
    "raw_erm = read_raw_ctf(erm_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46d7be4f-f4d6-4f28-8583-bd7182a755d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Info | 16 non-empty values\n",
      " bads: []\n",
      " ch_names: UDIO001, UPPT001, UTRG001, SCLK01-177, BG1-4408, BG2-4408, ...\n",
      " chs: 3 Stimulus, 32 misc, 26 Reference Magnetometers, 274 Magnetometers, 5 EEG\n",
      " comps: 5 items (list)\n",
      " ctf_head_t: CTF/4D/KIT head -> head transform\n",
      " custom_ref_applied: False\n",
      " dev_ctf_t: MEG device -> CTF/4D/KIT head transform\n",
      " dev_head_t: MEG device -> head transform\n",
      " dig: 263 items (3 Cardinal, 260 Extra)\n",
      " experimenter: EAB\n",
      " highpass: 0.0 Hz\n",
      " hpi_results: 1 item (list)\n",
      " lowpass: 1200.0 Hz\n",
      " meas_date: 2013-12-18 09:43:00 UTC\n",
      " meas_id: 4 items (dict)\n",
      " nchan: 340\n",
      " projs: []\n",
      " sfreq: 2400.0 Hz\n",
      " subject_info: <subject_info | his_id: S01>\n",
      ">\n"
     ]
    }
   ],
   "source": [
    "print(raw_combined.info) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17f201b7-4ccb-4350-97c1-1a9fdcfd4e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using qt as 2D backend.\n",
      "Using pyopengl with version 3.1.10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mne_qt_browser._pg_figure.MNEQtBrowser at 0x16b8674a0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_combined.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1eb36b29-d4cf-425e-8217-a85cc6d560a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      onset  duration  id    label\n",
      "0      7625      2776   1      BAD\n",
      "1    142459       892   1      BAD\n",
      "2    216954       460   1      BAD\n",
      "3    345135      5816   1      BAD\n",
      "4    357687      1053   1      BAD\n",
      "5    409101      3736   1      BAD\n",
      "6    461110       179   1      BAD\n",
      "7    479866       426   1      BAD\n",
      "8    764914     11500   1      BAD\n",
      "9    798174      6589   1      BAD\n",
      "10   846880      5383   1      BAD\n",
      "11   858863      5136   1      BAD\n",
      "0    864009      5583   1      BAD\n",
      "1    873256      3114   1      BAD\n",
      "2    878287      3456   1      BAD\n",
      "3    980432       228   1      BAD\n",
      "4    998489      1329   1      BAD\n",
      "5   1328527      4727   1      BAD\n",
      "6   1358136      4519   1      BAD\n",
      "7   1613288       189   1      BAD\n",
      "8   1652623      7937   1      BAD\n",
      "9    885179         0   1  saccade\n",
      "10   936993         0   1  saccade\n",
      "11   998527         0   1  saccade\n",
      "12  1060555         0   1  saccade\n",
      "13  1113894         0   1  saccade\n",
      "14  1207357         0   1  saccade\n",
      "15  1264771         0   1  saccade\n",
      "16  1314256         0   1  saccade\n",
      "17  1457101         0   1  saccade\n",
      "18  1597942         0   1  saccade\n",
      "19  1629939         0   1  saccade\n",
      "20  1653476         0   1  saccade\n",
      "21  1656852         0   1  saccade\n",
      "22  1697208         0   1  saccade\n",
      "23  1723869         0   1  saccade\n",
      "24  1726888         0   1  saccade\n"
     ]
    }
   ],
   "source": [
    "annotations_df = pd.DataFrame()\n",
    "\n",
    "for i in [1, 2]:\n",
    "    # read csv information about bad noisy segments\n",
    "    csv_fname = data_path / \"MEG\" / \"bst_auditory\" / f\"events_bad_0{i}.csv\"\n",
    "    df = pd.read_csv(csv_fname, names=[\"onset\", \"duration\", \"id\", \"label\"])\n",
    "\n",
    "    # add up the first run time to the second run onsets\n",
    "    df[\"onset\"] += run1_offset * (i - 1)\n",
    "\n",
    "    # concatenate bad segments of both runs\n",
    "    annotations_df = pd.concat([annotations_df, df], axis=0)\n",
    "\n",
    "print(annotations_df)\n",
    "\n",
    "saccades_events = df[df[\"label\"] == \"saccade\"].values[:, :3].astype(int)\n",
    "\n",
    "# Conversion from samples to times:\n",
    "onsets = annotations_df[\"onset\"].values / raw.info[\"sfreq\"]\n",
    "durations = annotations_df[\"duration\"].values / raw.info[\"sfreq\"]\n",
    "descriptions = annotations_df[\"label\"].values\n",
    "\n",
    "annotations = mne.Annotations(onsets, durations, descriptions)\n",
    "raw.set_annotations(annotations)\n",
    "del onsets, durations, descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de82de8-5087-4b58-943e-b243a50acc1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
